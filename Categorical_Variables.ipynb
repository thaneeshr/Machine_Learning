{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "A categorical variable takes only a limited number of values.\n",
    "\n",
    "Consider a survey that asks how often you eat breakfast and provides four options: \"Never\", \"Rarely\", \"Most days\", or \"Every day\". In this case, the data is categorical, because responses fall into a fixed set of categories.\n",
    "If people responded to a survey about which what brand of car they owned, the responses would fall into categories like \"Honda\", \"Toyota\", and \"Ford\". In this case, the data is also categorical.\n",
    "You will get an error if you try to plug these variables into most machine learning models in Python without preprocessing them first. In this tutorial, we'll compare three approaches that you can use to prepare your categorical data.\n",
    "\n",
    "Three Approaches\n",
    "### 1) Drop Categorical Variables\n",
    "The easiest approach to dealing with categorical variables is to simply remove them from the dataset. This approach will only work well if the columns did not contain useful information.\n",
    "\n",
    "### 2) Label Encoding\n",
    "Label encoding assigns each unique value to a different integer.\n",
    "\n",
    "tut3_labelencode\n",
    "\n",
    "This approach assumes an ordering of the categories: \"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3).\n",
    "\n",
    "This assumption makes sense in this example, because there is an indisputable ranking to the categories. Not all categorical variables have a clear ordering in the values, but we refer to those that do as ordinal variables. For tree-based models (like decision trees and random forests), you can expect label encoding to work well with ordinal variables.\n",
    "\n",
    "### 3) One-Hot Encoding\n",
    "One-hot encoding creates new columns indicating the presence (or absence) of each possible value in the original data. To understand this, we'll work through an example.\n",
    "\n",
    "tut3_onehot\n",
    "\n",
    "In the original dataset, \"Color\" is a categorical variable with three categories: \"Red\", \"Yellow\", and \"Green\". The corresponding one-hot encoding contains one column for each possible value, and one row for each row in the original dataset. Wherever the original value was \"Red\", we put a 1 in the \"Red\" column; if the original value was \"Yellow\", we put a 1 in the \"Yellow\" column, and so on.\n",
    "\n",
    "In contrast to label encoding, one-hot encoding does not assume an ordering of the categories. Thus, you can expect this approach to work particularly well if there is no clear ordering in the categorical data (e.g., \"Red\" is neither more nor less than \"Yellow\"). We refer to categorical variables without an intrinsic ranking as nominal variables.\n",
    "\n",
    "One-hot encoding generally does not perform well if the categorical variable takes on a large number of values (i.e., you generally won't use it for variables taking more than 15 different values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thane\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('D:\\ML\\melb_data.csv')\n",
    "\n",
    "# Separate target from predictors\n",
    "y = data.Price\n",
    "X = data.drop(['Price'], axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# Drop columns with missing values (simplest approach)\n",
    "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
    "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12167</td>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.98670</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6524</td>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.90050</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8413</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.82200</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2919</td>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.91580</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6043</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.82720</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13123</td>\n",
       "      <td>h</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-37.77695</td>\n",
       "      <td>144.95785</td>\n",
       "      <td>11918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3264</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Eastern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>-37.74160</td>\n",
       "      <td>145.04810</td>\n",
       "      <td>2947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9845</td>\n",
       "      <td>h</td>\n",
       "      <td>PI</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>-37.73572</td>\n",
       "      <td>144.97256</td>\n",
       "      <td>11204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10799</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>-37.72057</td>\n",
       "      <td>145.02615</td>\n",
       "      <td>21650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2732</td>\n",
       "      <td>h</td>\n",
       "      <td>SP</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>-37.79430</td>\n",
       "      <td>144.88750</td>\n",
       "      <td>7570.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10864 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n",
       "12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n",
       "6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n",
       "8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n",
       "2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n",
       "6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n",
       "...    ...    ...                    ...    ...       ...       ...       ...   \n",
       "13123    h     SP  Northern Metropolitan      3       5.2    3056.0       3.0   \n",
       "3264     h      S   Eastern Metropolitan      3      10.5    3081.0       3.0   \n",
       "9845     h     PI  Northern Metropolitan      4       6.7    3058.0       4.0   \n",
       "10799    h      S  Northern Metropolitan      3      12.0    3073.0       3.0   \n",
       "2732     h     SP   Western Metropolitan      4       6.4    3011.0       4.0   \n",
       "\n",
       "       Bathroom  Landsize  Lattitude  Longtitude  Propertycount  \n",
       "12167       1.0       0.0  -37.85984   144.98670        13240.0  \n",
       "6524        2.0     193.0  -37.85800   144.90050         6380.0  \n",
       "8413        1.0     555.0  -37.79880   144.82200         3755.0  \n",
       "2919        1.0     265.0  -37.70830   144.91580         8870.0  \n",
       "6043        1.0     673.0  -37.76230   144.82720         4217.0  \n",
       "...         ...       ...        ...         ...            ...  \n",
       "13123       1.0     212.0  -37.77695   144.95785        11918.0  \n",
       "3264        1.0     748.0  -37.74160   145.04810         2947.0  \n",
       "9845        2.0     441.0  -37.73572   144.97256        11204.0  \n",
       "10799       1.0     606.0  -37.72057   145.02615        21650.0  \n",
       "2732        2.0     319.0  -37.79430   144.88750         7570.0  \n",
       "\n",
       "[10864 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type              True\n",
       "Method            True\n",
       "Regionname        True\n",
       "Rooms            False\n",
       "Distance         False\n",
       "Postcode         False\n",
       "Bedroom2         False\n",
       "Bathroom         False\n",
       "Landsize         False\n",
       "Lattitude        False\n",
       "Longtitude       False\n",
       "Propertycount    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Method', 'Regionname'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score from Approach 1 (Drop Categorical Variables)\n",
    "We drop the object columns with the select_dtypes() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "175703.48185157913\n"
     ]
    }
   ],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score from Approach 2 (Label Encoding)¶\n",
    "Scikit-learn has a LabelEncoder class that can be used to get label encodings. We loop over the categorical variables and apply the label encoder separately to each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2(Label Encoding):\n",
      "165936.40548390493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_X_train =X_train.copy()\n",
    "label_X_valid=X_valid.copy()\n",
    "le=LabelEncoder()\n",
    "for col in object_cols:\n",
    "    label_X_train[col]=le.fit_transform(X_train[col])\n",
    "    label_X_valid[col]=le.transform(X_valid[col])\n",
    "print(\"MAE from Approach 2(Label Encoding):\")\n",
    "print(score_dataset(label_X_train,label_X_valid,y_train,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell above, for each column, we randomly assign each unique value to a different integer. This is a common approach that is simpler than providing custom labels; however, we can expect an additional boost in performance if we provide better-informed labels for all ordinal variables.\n",
    "\n",
    "### Score from Approach 3 (One-Hot Encoding)\n",
    "We use the OneHotEncoder class from scikit-learn to get one-hot encodings. There are a number of parameters that can be used to customize its behavior.\n",
    "\n",
    "We set handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the training data, and\n",
    "setting sparse=False ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix).\n",
    "To use the encoder, we supply only the categorical columns that we want to be one-hot encoded. For instance, to encode the training data, we supply X_train[object_cols]. (object_cols in the code cell below is a list of the column names with categorical data, and so X_train[object_cols] contains all of the categorical data in the training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One -Hot Encoding)\n",
      "166089.4893009678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "o_encoder=OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "o_cols_train=pd.DataFrame(o_encoder.fit_transform(X_train[object_cols]))\n",
    "o_cols_valid=pd.DataFrame(o_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "o_cols_train.index=X_train.index\n",
    "o_cols_valid.index=X_valid.index\n",
    "\n",
    "num_X_train =X_train.drop(object_cols,axis=1)\n",
    "num_X_valid=X_valid.drop(object_cols,axis=1)\n",
    "\n",
    "o_X_train=pd.concat([num_X_train,o_cols_train],axis=1)\n",
    "o_X_valid=pd.concat([num_X_valid,o_cols_valid],axis=1)\n",
    "\n",
    "print(\"MAE from Approach 3 (One -Hot Encoding)\")\n",
    "print(score_dataset(o_X_train,o_X_valid,y_train,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
